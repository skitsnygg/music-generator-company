name: Scheduled Drops (Prod)

on:
  schedule:
    # 09:00 America/Sao_Paulo == 12:00 UTC (GitHub cron is UTC)
    - cron: "0 12 * * *"
  workflow_dispatch:

concurrency:
  group: scheduled-drops-prod
  cancel-in-progress: false

jobs:
  drop:
    runs-on: [self-hosted, mgc-prod]

    env:
      # Persistent prod DB
      MGC_DB: /var/lib/mgc/db.sqlite

      # Pin provider for scheduled runs so we never depend on repo-local data/tracks/*
      # (Flip this later when you intentionally move prod to riffusion/filesystem provider.)
      MGC_PROVIDER: stub

      # Keep these for later if/when you switch to filesystem provider
      MGC_FS_PROVIDER_DIR: /var/lib/mgc/audio_pool

      # Ensure scheduled runs use real time (not deterministic CI time)
      MGC_DETERMINISTIC: ""
      MGC_FIXED_TIME: ""

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Preflight
        shell: bash
        run: |
          set -euxo pipefail
          whoami
          id
          uname -a || true
          df -h || true
          timedatectl || true

          echo "MGC_DB=$MGC_DB"
          ls -la "$(dirname "$MGC_DB")" || true
          test -f "$MGC_DB"

          echo "MGC_PROVIDER=$MGC_PROVIDER"
          echo "MGC_FS_PROVIDER_DIR=$MGC_FS_PROVIDER_DIR"
          ls -la "$MGC_FS_PROVIDER_DIR" || true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        shell: bash
        run: |
          set -euxo pipefail
          python -m pip install -U pip
          python -m pip install -e .
          python -c "import mgc; print('mgc:', mgc.__file__)"

      - name: DB migrate
        shell: bash
        run: |
          set -euxo pipefail
          python -m mgc.main --db "$MGC_DB" db migrate
          python -m mgc.main --db "$MGC_DB" db status --json

      - name: Provider check (non-blocking)
        shell: bash
        continue-on-error: true
        run: |
          set -euxo pipefail
          python -m mgc.main --db "$MGC_DB" providers check --json || true

      - name: Run autonomous drop (end-to-end)
        shell: bash
        run: |
          set -euxo pipefail

          OUT_DIR="/tmp/mgc_prod_autonomous"
          WEB_OUT_DIR="/tmp/mgc_prod_autonomous_web"

          rm -rf "$OUT_DIR" "$WEB_OUT_DIR"
          mkdir -p "$OUT_DIR" "$WEB_OUT_DIR"

          # Provider is pinned via env (MGC_PROVIDER=stub)
          python -m mgc.main --db "$MGC_DB" run autonomous \
            --context focus \
            --seed 1 \
            --out-dir "$OUT_DIR" \
            --with-web \
            --web-out-dir "$WEB_OUT_DIR" \
            --contract local \
            --json | tee "$OUT_DIR/autonomous.json"

          echo "Autonomous outputs:"
          find "$OUT_DIR" -maxdepth 3 -type f | sed -n '1,200p' || true
          find "$WEB_OUT_DIR" -maxdepth 3 -type f | sed -n '1,200p' || true

      - name: Upload prod artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scheduled-drop-artifacts-prod
          path: |
            /tmp/mgc_prod_autonomous/**
            /tmp/mgc_prod_autonomous_web/**
            data/submissions/**
          if-no-files-found: warn

      - name: Promote release to /var/lib/mgc/releases
        shell: bash
        run: |
          set -euxo pipefail

          OUT_DIR="/tmp/mgc_prod_autonomous"
          WEB_OUT_DIR="/tmp/mgc_prod_autonomous_web"
          AUTON_JSON="$OUT_DIR/autonomous.json"

          test -f "$AUTON_JSON"

          # Parse drop_id from autonomous.json (no heredoc; avoids YAML indentation pitfalls)
          DROP_ID="$(python -c 'import json; p="'"$AUTON_JSON"'"; obj=json.load(open(p,"r",encoding="utf-8")); print(obj["drop"]["ids"]["drop_id"])')"
          echo "DROP_ID=$DROP_ID"

          RELEASE_ROOT="/var/lib/mgc/releases"
          RELEASE_DIR="$RELEASE_ROOT/$DROP_ID"

          sudo mkdir -p "$RELEASE_DIR/web" "$RELEASE_DIR/submission" "$RELEASE_DIR/run"

          # Copy web bundle
          sudo rsync -a --delete "$WEB_OUT_DIR/" "$RELEASE_DIR/web/"

          # Copy submission artifacts (zip + receipts)
          sudo rsync -a "data/submissions/$DROP_ID/" "$RELEASE_DIR/submission/"

          # Copy run evidence for convenience
          sudo rsync -a "$OUT_DIR/" "$RELEASE_DIR/run/"

          # Update latest symlink atomically
          sudo ln -sfn "$RELEASE_DIR" "$RELEASE_ROOT/latest"

          # Fix perms so nginx can read
          sudo chmod -R a+rX "$RELEASE_DIR"

          echo "Promoted release: $RELEASE_DIR"
          echo "Latest -> $(readlink -f "$RELEASE_ROOT/latest")"
