name: Scheduled Drops (Prod)

on:
  schedule:
    # 09:00 America/Sao_Paulo == 12:00 UTC (but GitHub cron is UTC)
    - cron: "0 12 * * *"
  workflow_dispatch:

concurrency:
  group: scheduled-drops-prod
  cancel-in-progress: false

jobs:
  drop:
    runs-on: [self-hosted, mgc-prod]

    env:
      # Use the persistent prod DB
      MGC_DB: /var/lib/mgc/db.sqlite

      # Keep these set if you want filesystem provider later, but do NOT hard-fail if empty.
      # If your provider is still stub in prod, leaving these set won't hurt, but they may be unused.
      MGC_PROVIDER: filesystem
      MGC_FS_PROVIDER_DIR: /var/lib/mgc/audio_pool

      # Ensure scheduled runs use real time (not deterministic CI time)
      MGC_DETERMINISTIC: ""
      MGC_FIXED_TIME: ""

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Preflight
        shell: bash
        run: |
          set -euxo pipefail
          whoami
          id
          uname -a || true
          df -h || true
          timedatectl || true

          echo "MGC_DB=$MGC_DB"
          ls -la "$(dirname "$MGC_DB")" || true
          test -f "$MGC_DB"

          echo "MGC_FS_PROVIDER_DIR=$MGC_FS_PROVIDER_DIR"
          ls -la "$MGC_FS_PROVIDER_DIR" || true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        shell: bash
        run: |
          set -euxo pipefail
          python -m pip install -U pip
          python -m pip install -e .
          python -c "import mgc; print('mgc:', mgc.__file__)"

      - name: DB migrate
        shell: bash
        run: |
          set -euxo pipefail
          python -m mgc.main --db "$MGC_DB" db migrate
          python -m mgc.main --db "$MGC_DB" db status --json

      - name: Provider check
        shell: bash
        continue-on-error: true
        run: |
          set -euxo pipefail
          python -m mgc.main --db "$MGC_DB" providers check --json

      - name: Run autonomous drop (end-to-end)
        shell: bash
        run: |
          set -euxo pipefail

          OUT_DIR="/tmp/mgc_prod_autonomous"
          WEB_OUT_DIR="/tmp/mgc_prod_autonomous_web"

          rm -rf "$OUT_DIR" "$WEB_OUT_DIR"
          mkdir -p "$OUT_DIR" "$WEB_OUT_DIR"

          # Run the full cron-safe pipeline.
          # - contract local: validates presence + submission_zip without requiring publish contract inputs.
          MGC_PROVIDER=stub python -m mgc.main --db "$MGC_DB" run autonomous \
            --context focus \
            --seed 1 \
            --out-dir "$OUT_DIR" \
            --with-web \
            --web-out-dir "$WEB_OUT_DIR" \
            --contract local \
            --json | tee "$OUT_DIR/autonomous.json"


          echo "Autonomous outputs:"
          find "$OUT_DIR" -maxdepth 3 -type f | sed -n '1,200p' || true
          find "$WEB_OUT_DIR" -maxdepth 3 -type f | sed -n '1,200p' || true

      - name: Upload prod artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scheduled-drop-artifacts-prod
          path: |
            /tmp/mgc_prod_autonomous/**
            /tmp/mgc_prod_autonomous_web/**
            data/submissions/**
          if-no-files-found: warn

      - name: Promote release to /var/lib/mgc/releases
        shell: bash
        run: |
          set -euxo pipefail

          OUT_DIR="/tmp/mgc_prod_autonomous"
          WEB_OUT_DIR="/tmp/mgc_prod_autonomous_web"

          # Parse drop_id from the autonomous output JSON
          DROP_ID="$(python - <<'PY'

import json
p="/tmp/mgc_prod_autonomous/autonomous.json"
with open(p,"r",encoding="utf-8") as f:
    obj=json.load(f)
print(obj["drop"]["ids"]["drop_id"])
PY
          )"

          RELEASE_ROOT="/var/lib/mgc/releases"
          RELEASE_DIR="$RELEASE_ROOT/$DROP_ID"

          sudo mkdir -p "$RELEASE_DIR"
          sudo mkdir -p "$RELEASE_DIR/web"

          # Copy web bundle
          sudo rsync -a --delete "$WEB_OUT_DIR/" "$RELEASE_DIR/web/"

          # Copy submission artifacts (zip + receipts)
          sudo mkdir -p "$RELEASE_DIR/submission"
          sudo rsync -a "data/submissions/$DROP_ID/" "$RELEASE_DIR/submission/"

          # Copy evidence for convenience
          sudo rsync -a "$OUT_DIR/" "$RELEASE_DIR/run/"

          # Update latest symlink atomically
          sudo ln -sfn "$RELEASE_DIR" "$RELEASE_ROOT/latest"

          # Fix perms so the web server can read
          sudo chmod -R a+rX "$RELEASE_DIR"

          echo "Promoted release: $RELEASE_DIR"
          echo "Latest -> $(readlink -f "$RELEASE_ROOT/latest")"
