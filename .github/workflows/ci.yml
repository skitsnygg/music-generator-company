# .github/workflows/ci.yml
name: CI

on:
  push:
    branches: [main]
  pull_request:

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

jobs:
  ci:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    env:
      # Determinism knobs for everything in this workflow
      MGC_DETERMINISTIC: "1"
      MGC_FIXED_TIME: "2020-01-01T00:00:00Z"
      # Deterministic migrations
      MGC_MIGRATE_NOW: "2020-01-01T00:00:00Z"
      PYTHON: python

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set temp dirs
        shell: bash
        run: |
          set -euxo pipefail
          echo "MGC_EVIDENCE_DIR=${RUNNER_TEMP}/mgc_evidence" >> "$GITHUB_ENV"
          echo "MGC_ARTIFACTS_DIR=${RUNNER_TEMP}/artifacts/ci" >> "$GITHUB_ENV"
          echo "MGC_WEB_DIR=${RUNNER_TEMP}/mgc_web" >> "$GITHUB_ENV"
          mkdir -p \
            "${RUNNER_TEMP}/mgc_evidence" \
            "${RUNNER_TEMP}/artifacts/ci" \
            "${RUNNER_TEMP}/mgc_web"

      - name: Prepare temp dirs
        shell: bash
        run: |
          set -euxo pipefail
          mkdir -p "${MGC_ARTIFACTS_DIR}" "${MGC_EVIDENCE_DIR}" "${MGC_WEB_DIR}"
          echo "placeholder" > "${MGC_ARTIFACTS_DIR}/.keep"
          ls -la "${MGC_ARTIFACTS_DIR}"
          ls -la "${MGC_EVIDENCE_DIR}"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        shell: bash
        run: |
          set -euxo pipefail
          python -m pip install -U pip
          python -m pip install -e .

      - name: Install ffmpeg (ffmpeg + ffprobe)
        shell: bash
        run: |
          set -euxo pipefail
          sudo apt-get update
          sudo apt-get install -y ffmpeg
          ffmpeg -version
          ffprobe -version

      - name: Build fixture DB (copy to temp; reset repo file)
        shell: bash
        run: |
          set -euxo pipefail

          python scripts/make_fixture_db.py

          ls -la fixtures
          sha256sum fixtures/ci_db.sqlite

          cp -f fixtures/ci_db.sqlite "${RUNNER_TEMP}/ci_db.sqlite"
          echo "MGC_DB=${RUNNER_TEMP}/ci_db.sqlite" >> "$GITHUB_ENV"

          # Keep checkout clean
          git checkout -- fixtures/ci_db.sqlite || true

          ls -la "${RUNNER_TEMP}/ci_db.sqlite"
          sha256sum "${RUNNER_TEMP}/ci_db.sqlite"

      - name: Run DB migrations on temp DB (deterministic)
        shell: bash
        env:
          MGC_DB: ${{ env.MGC_DB }}
          MGC_MIGRATE_NOW: ${{ env.MGC_MIGRATE_NOW }}
        run: |
          set -euxo pipefail

          test -n "${MGC_DB}"
          test -f "${MGC_DB}"

          python scripts/migrate_db.py

          # Sanity: billing revocations table should exist once migrations run
          sqlite3 "${MGC_DB}" ".schema billing_token_revocations" >/dev/null

      - name: Ensure DB schema has required tables (CI bootstrap)
        shell: bash
        run: |
          set -euxo pipefail
          python - <<'PY'
          import os, sqlite3

          p = os.environ["MGC_DB"]
          con = sqlite3.connect(p)
          try:
              con.execute("PRAGMA foreign_keys = ON")
              con.executescript("""
              CREATE TABLE IF NOT EXISTS tracks (
                track_id TEXT PRIMARY KEY,
                ts TEXT NOT NULL,
                title TEXT,
                provider TEXT,
                mood TEXT,
                genre TEXT,
                artifact_path TEXT,
                meta TEXT
              );

              CREATE TABLE IF NOT EXISTS drops (
                drop_id TEXT PRIMARY KEY,
                ts TEXT NOT NULL,
                context TEXT,
                seed TEXT,
                run_id TEXT,
                track_id TEXT,
                meta TEXT
              );

              CREATE TABLE IF NOT EXISTS events (
                event_id TEXT PRIMARY KEY,
                ts TEXT NOT NULL,
                kind TEXT,
                actor TEXT,
                meta TEXT
              );

              CREATE TABLE IF NOT EXISTS marketing_posts (
                post_id TEXT PRIMARY KEY,
                ts TEXT NOT NULL,
                platform TEXT,
                status TEXT,
                content TEXT,
                meta TEXT
              );

              CREATE TABLE IF NOT EXISTS playlists (
                playlist_id TEXT PRIMARY KEY,
                ts TEXT,
                context TEXT,
                payload TEXT,
                meta TEXT
              );
              """)
              con.commit()

              tables = [r[0] for r in con.execute(
                  "SELECT name FROM sqlite_master WHERE type='table' ORDER BY name"
              ).fetchall()]
              print("tables:", tables)
              required = {"tracks", "drops", "events", "marketing_posts", "playlists"}
              missing = sorted(required - set(tables))
              assert not missing, f"missing tables: {missing}"
          finally:
              con.close()
          PY

      - name: Preflight DB (must pass)
        shell: bash
        run: |
          set -euxo pipefail
          echo "HEAD=$(git rev-parse HEAD)"
          echo "MGC_DB=$MGC_DB"

          python - <<'PY'
          import os, sqlite3, sys
          p = os.environ["MGC_DB"]
          con = sqlite3.connect(p)
          try:
              tables = [r[0] for r in con.execute(
                  "select name from sqlite_master where type='table' order by name"
              ).fetchall()]
              print("tables:", tables)
              required = {"tracks", "drops", "events", "marketing_posts", "playlists"}
              missing = sorted(required - set(tables))
              if missing:
                  print(f"ERROR: {p} missing tables: {missing}", file=sys.stderr)
                  sys.exit(1)
          finally:
              con.close()
          PY

      # -----------------------------
      # FAST gate: PRs and main
      # -----------------------------
      - name: Run CI gate (fast; twice)
        shell: bash
        env:
          MGC_DB: ${{ env.MGC_DB }}
          MGC_ARTIFACTS_DIR: ${{ env.MGC_ARTIFACTS_DIR }}
          MGC_EVIDENCE_DIR: ${{ env.MGC_EVIDENCE_DIR }}
          MGC_CI_MODE: "fast"
        run: |
          set -euxo pipefail
          bash scripts/ci_gate.sh
          bash scripts/ci_gate.sh

      - name: Verify DB track paths exist (non-empty only)
        shell: bash
        env:
          MGC_DB: ${{ env.MGC_DB }}
        run: |
          set -euxo pipefail
          python scripts/verify_track_paths.py \
            --db "${MGC_DB}" \
            --repo-root .

      # -----------------------------
      # FULL gate: only on main pushes
      # -----------------------------
      - name: Run CI gate (full; once)
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        shell: bash
        env:
          MGC_DB: ${{ env.MGC_DB }}
          MGC_ARTIFACTS_DIR: ${{ env.MGC_ARTIFACTS_DIR }}
          MGC_EVIDENCE_DIR: ${{ env.MGC_EVIDENCE_DIR }}
          MGC_CI_MODE: "full"
        run: |
          set -euxo pipefail
          bash scripts/ci_gate.sh

      # -----------------------------
      # Extra checks: main only
      # -----------------------------
      - name: Run determinism gate (existing)
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        shell: bash
        env:
          MGC_DB: ${{ env.MGC_DB }}
          MGC_ARTIFACTS_DIR: ${{ env.MGC_ARTIFACTS_DIR }}
          MGC_EVIDENCE_DIR: ${{ env.MGC_EVIDENCE_DIR }}
        run: |
          set -euxo pipefail
          bash scripts/ci_run_determinism.sh

      - name: Publish-marketing determinism (weekly; file mode; dry-run)
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        shell: bash
        env:
          MGC_DB: ${{ env.MGC_DB }}
          MGC_ARTIFACTS_DIR: ${{ env.MGC_ARTIFACTS_DIR }}
          MGC_FIXED_TIME: ${{ env.MGC_FIXED_TIME }}
        run: |
          set -euxo pipefail

          PERIOD_KEY="$(python - <<'PY'
          from datetime import datetime, timezone
          import os

          raw = (os.environ.get("MGC_FIXED_TIME") or "2020-01-01T00:00:00Z").strip()
          if raw.endswith("Z"):
              raw = raw[:-1] + "+00:00"
          dt = datetime.fromisoformat(raw)
          if dt.tzinfo is None:
              dt = dt.replace(tzinfo=timezone.utc)
          else:
              dt = dt.astimezone(timezone.utc)

          y, w, _ = dt.isocalendar()
          print(f"{y}-W{w:02d}")
          PY
          )"
          echo "PERIOD_KEY=${PERIOD_KEY}"

          WEEKLY1="${MGC_ARTIFACTS_DIR}/weekly_pub_1"
          WEEKLY2="${MGC_ARTIFACTS_DIR}/weekly_pub_2"
          OUT1="${MGC_ARTIFACTS_DIR}/publish_weekly_1"
          OUT2="${MGC_ARTIFACTS_DIR}/publish_weekly_2"

          rm -rf "${WEEKLY1}" "${WEEKLY2}" "${OUT1}" "${OUT2}"
          mkdir -p "${WEEKLY1}" "${WEEKLY2}" "${OUT1}" "${OUT2}"

          python -m mgc.main --db "${MGC_DB}" --seed 1 run weekly \
            --context focus --out-dir "${WEEKLY1}" --deterministic --period-key "${PERIOD_KEY}"

          python -m mgc.main --db "${MGC_DB}" --seed 1 run weekly \
            --context focus --out-dir "${WEEKLY2}" --deterministic --period-key "${PERIOD_KEY}"

          python -m mgc.main --db "${MGC_DB}" run publish-marketing \
            --bundle-dir "${WEEKLY1}/drop_bundle" --deterministic --dry-run \
            --out-dir "${OUT1}" \
            --json

          python -m mgc.main --db "${MGC_DB}" run publish-marketing \
            --bundle-dir "${WEEKLY2}/drop_bundle" --deterministic --dry-run \
            --out-dir "${OUT2}" \
            --json

          diff -ru "${OUT1}" "${OUT2}"

      - name: Weekly marketing receipts + submission determinism (file mode)
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        shell: bash
        env:
          MGC_DB: ${{ env.MGC_DB }}
          MGC_FIXED_TIME: ${{ env.MGC_FIXED_TIME }}
          MGC_DETERMINISTIC: ${{ env.MGC_DETERMINISTIC }}
        run: |
          set -euxo pipefail

          OUT1="${RUNNER_TEMP}/mgc_weekly_marketing_1"
          OUT2="${RUNNER_TEMP}/mgc_weekly_marketing_2"
          rm -rf "${OUT1}" "${OUT2}"
          mkdir -p "${OUT1}" "${OUT2}"

          # Build the same weekly bundle twice
          python -m mgc.main --db "${MGC_DB}" --seed 1 run weekly \
            --context focus --out-dir "${OUT1}" --deterministic --period-key 2020-W01

          python -m mgc.main --db "${MGC_DB}" --seed 1 run weekly \
            --context focus --out-dir "${OUT2}" --deterministic --period-key 2020-W01

          # Write receipts into each out_dir (dry-run but writes deterministic receipts)
          python -m mgc.main --db "${MGC_DB}" run publish-marketing \
            --bundle-dir "${OUT1}/drop_bundle" --deterministic --dry-run --out-dir "${OUT1}" \
            --json

          python -m mgc.main --db "${MGC_DB}" run publish-marketing \
            --bundle-dir "${OUT2}/drop_bundle" --deterministic --dry-run --out-dir "${OUT2}" \
            --json

          # Build submission zips
          python -m mgc.main submission build --bundle-dir "${OUT1}/drop_bundle" --out "${OUT1}/submission.zip"
          python -m mgc.main submission build --bundle-dir "${OUT2}/drop_bundle" --out "${OUT2}/submission.zip"

          test -s "${OUT1}/submission.zip"
          test -s "${OUT2}/submission.zip"

          # Determinism: receipts trees and zips must match
          diff -ru "${OUT1}/marketing/receipts" "${OUT2}/marketing/receipts"
          sha256sum "${OUT1}/submission.zip" "${OUT2}/submission.zip"
          test "$(sha256sum "${OUT1}/submission.zip" | awk '{print $1}')" = "$(sha256sum "${OUT2}/submission.zip" | awk '{print $1}')"

      - name: Web player build (from evidence)
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        shell: bash
        env:
          WEB_DIR: ${{ env.MGC_WEB_DIR }}
          MGC_ARTIFACTS_DIR: ${{ env.MGC_ARTIFACTS_DIR }}
          MGC_EVIDENCE_DIR: ${{ env.MGC_EVIDENCE_DIR }}
        run: |
          set -euxo pipefail

          rm -rf "${WEB_DIR}"
          mkdir -p "${WEB_DIR}"

          # Evidence may be written to different roots depending on CI mode; locate it robustly.
          EVIDENCE_PATH=""
          for p in \
            "${MGC_ARTIFACTS_DIR}/auto/drop_evidence.json" \
            "${MGC_EVIDENCE_DIR}/drop_evidence.json" \
            "${MGC_EVIDENCE_DIR}/auto/drop_evidence.json"
          do
            if test -s "${p}"; then
              EVIDENCE_PATH="${p}"
              break
            fi
          done

          if test -z "${EVIDENCE_PATH}"; then
            # As a last resort, search (bounded) for drop_evidence.json in runner temp.
            EVIDENCE_PATH="$(find "${RUNNER_TEMP}" -maxdepth 6 -type f -name 'drop_evidence.json' -size +0c 2>/dev/null | head -n 1 || true)"
          fi

          if test -z "${EVIDENCE_PATH}"; then
            echo "ERROR: drop_evidence.json not found. Looked in:"
            echo "  ${MGC_ARTIFACTS_DIR}/auto/drop_evidence.json"
            echo "  ${MGC_EVIDENCE_DIR}/drop_evidence.json"
            echo "  ${MGC_EVIDENCE_DIR}/auto/drop_evidence.json"
            echo "and searched under RUNNER_TEMP."
            echo "Debug listing:"
            ls -la "${MGC_ARTIFACTS_DIR}" || true
            find "${MGC_ARTIFACTS_DIR}" -maxdepth 4 -type f -name '*evidence*.json' -print || true
            ls -la "${MGC_EVIDENCE_DIR}" || true
            find "${MGC_EVIDENCE_DIR}" -maxdepth 4 -type f -name '*evidence*.json' -print || true
            exit 1
          fi

          echo "EVIDENCE_PATH=${EVIDENCE_PATH}"
          export EVIDENCE_PATH

          PLAYLIST_PATH="$(python - <<'PY'
          import json, os, sys
          from pathlib import Path

          evidence_path = Path(os.environ["EVIDENCE_PATH"]).resolve()
          obj = json.loads(evidence_path.read_text(encoding="utf-8"))

          def dig(d, *keys):
              cur = d
              for k in keys:
                  if not isinstance(cur, dict) or k not in cur:
                      return None
                  cur = cur[k]
              return cur

          # Primary: playlist path embedded in evidence (daily/autonomous style)
          candidates = [
              dig(obj, "paths", "playlist_path"),
              dig(obj, "paths", "playlist"),
              dig(obj, "paths", "playlist_json"),
              dig(obj, "paths", "playlist_file"),
              dig(obj, "drop", "paths", "playlist_path"),
              dig(obj, "drop", "paths", "playlist"),
              obj.get("playlist_path") if isinstance(obj, dict) else None,
              obj.get("playlist") if isinstance(obj, dict) else None,
          ]

          raw = None
          for c in candidates:
              if isinstance(c, str) and c.strip():
                  raw = c.strip()
                  break

          if raw:
              p = Path(raw)
              if not p.is_absolute():
                  p = (evidence_path.parent / p).resolve()
              if p.exists() and p.stat().st_size > 0:
                  print(str(p))
                  raise SystemExit(0)

          # Fallback: weekly evidence may not include a playlist path.
          # Search for playlist json near the evidence file.
          root = evidence_path.parent
          near = [
              root / "playlist.json",
              root / "drop_bundle" / "playlist.json",
              root.parent / "playlist.json",
              root.parent / "drop_bundle" / "playlist.json",
          ]
          for p in near:
              if p.exists() and p.stat().st_size > 0:
                  print(str(p.resolve()))
                  raise SystemExit(0)

          # Last resort: bounded search for playlist*.json near evidence root.
          search_roots = [root, root.parent]
          for sr in search_roots:
              if not sr.exists():
                  continue
              for p in sr.rglob("playlist*.json"):
                  try:
                      if p.is_file() and p.stat().st_size > 0:
                          print(str(p.resolve()))
                          raise SystemExit(0)
                  except OSError:
                      continue

          print("ERROR: Could not find playlist path in evidence or nearby files.", file=sys.stderr)
          print(f"evidence_path={evidence_path}", file=sys.stderr)
          raise SystemExit(2)
          PY
          )"

          echo "PLAYLIST_PATH=${PLAYLIST_PATH}"
          test -n "${PLAYLIST_PATH}"
          test -s "${PLAYLIST_PATH}"

          python -m mgc.main web build \
            --playlist "${PLAYLIST_PATH}" \
            --out-dir "${WEB_DIR}" \
            --prefer-mp3 \
            --clean \
            --fail-if-empty \
            --json

          test "$(find "${WEB_DIR}" -maxdepth 6 -type f -name 'index.html' | wc -l)" -ge 1
          test "$(find "${WEB_DIR}" -maxdepth 8 -type f \( -name '*.mp3' -o -name '*.wav' \) | wc -l)" -ge 1

      - name: Ensure working tree is clean (no generated artifacts)
        shell: bash
        run: |
          set -euo pipefail
          git status --porcelain=v1
          test -z "$(git status --porcelain=v1)"

      - name: Upload artifacts (on failure)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: ci-artifacts
          if-no-files-found: ignore
          path: |
            ${{ env.MGC_ARTIFACTS_DIR }}
            ${{ env.MGC_EVIDENCE_DIR }}
            ${{ env.MGC_WEB_DIR }}
