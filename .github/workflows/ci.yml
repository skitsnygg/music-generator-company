name: CI

on:
  push:
    branches: [main]
  pull_request:

jobs:
  ci:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set temp dirs
        shell: bash
        run: |
          set -euxo pipefail
          echo "MGC_EVIDENCE_DIR=${RUNNER_TEMP}/mgc_evidence" >> "$GITHUB_ENV"
          echo "MGC_ARTIFACTS_DIR=${RUNNER_TEMP}/artifacts/ci" >> "$GITHUB_ENV"
          mkdir -p "${RUNNER_TEMP}/mgc_evidence" "${RUNNER_TEMP}/artifacts/ci"

      - name: Prepare temp dirs (always)
        shell: bash
        run: |
          set -euxo pipefail
          mkdir -p "${MGC_ARTIFACTS_DIR}" "${MGC_EVIDENCE_DIR}"
          echo "placeholder" > "${MGC_ARTIFACTS_DIR}/.keep"
          ls -la "${MGC_ARTIFACTS_DIR}"
          ls -la "${MGC_EVIDENCE_DIR}"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        shell: bash
        run: |
          set -euxo pipefail
          python -m pip install -U pip
          python -m pip install -e .

      - name: Install ffmpeg (ffmpeg + ffprobe)
        shell: bash
        run: |
          set -euxo pipefail
          sudo apt-get update
          sudo apt-get install -y ffmpeg
          ffmpeg -version
          ffprobe -version

      - name: Build fixture DB (copy to temp; reset repo file)
        shell: bash
        run: |
          set -euxo pipefail
          python scripts/make_fixture_db.py

          ls -la fixtures
          sha256sum fixtures/ci_db.sqlite

          cp -f fixtures/ci_db.sqlite "${RUNNER_TEMP}/ci_db.sqlite"
          echo "MGC_DB=${RUNNER_TEMP}/ci_db.sqlite" >> "$GITHUB_ENV"

          git checkout -- fixtures/ci_db.sqlite || true

          ls -la "${RUNNER_TEMP}/ci_db.sqlite"
          sha256sum "${RUNNER_TEMP}/ci_db.sqlite"

      - name: Preflight DB (must pass)
        shell: bash
        run: |
          set -euxo pipefail
          echo "HEAD=$(git rev-parse HEAD)"
          echo "MGC_DB=$MGC_DB"

          python - <<'PY'
          import os, sqlite3, sys
          p = os.environ["MGC_DB"]
          con = sqlite3.connect(p)
          try:
              tables = [r[0] for r in con.execute("select name from sqlite_master where type='table' order by name").fetchall()]
              print("tables:", tables)
              if "playlists" not in tables:
                  print(f"ERROR: {p} missing playlists table", file=sys.stderr)
                  sys.exit(1)
          finally:
              con.close()
          PY

      - name: Run CI gate (twice)
        shell: bash
        run: |
          set -euxo pipefail
          bash scripts/ci_gate.sh
          bash scripts/ci_gate.sh

      - name: Run determinism gate (run daily/publish/manifest + drop/drops + replay diff)
        shell: bash
        env:
          MGC_DETERMINISTIC: "1"
          MGC_FIXED_TIME: "2020-01-01T00:00:00Z"
          MGC_ARTIFACTS_DIR: ${{ env.MGC_ARTIFACTS_DIR }}
          MGC_EVIDENCE_DIR: ${{ env.MGC_EVIDENCE_DIR }}
          MGC_DB: ${{ env.MGC_DB }}
        run: |
          set -euxo pipefail

          bash scripts/ci_run_determinism.sh

          python -m mgc.main run drop \
            --context focus \
            --seed 1 \
            --deterministic \
            --out-dir "${MGC_EVIDENCE_DIR}" \
            > /tmp/mgc_drop.json
          python -m json.tool < /tmp/mgc_drop.json > /dev/null

          python -m mgc.main --json drops list --limit 1 > /tmp/mgc_drops_list.json
          python -m json.tool < /tmp/mgc_drops_list.json > /dev/null

          if command -v jq >/dev/null 2>&1; then
            DROP_ID="$(jq -r '.drop.id' /tmp/mgc_drop.json)"
            test -n "$DROP_ID" && test "$DROP_ID" != "null"
            python -m mgc.main --json drops show "$DROP_ID" > /tmp/mgc_drops_show.json
            python -m json.tool < /tmp/mgc_drops_show.json > /dev/null
          fi

          mkdir -p "${MGC_ARTIFACTS_DIR}"
          python -m mgc.main --log-level INFO run drop --context focus --seed 1 --deterministic --out-dir "${MGC_EVIDENCE_DIR}" \
            > "${MGC_ARTIFACTS_DIR}/drop1.json"
          python -m mgc.main --log-level INFO run drop --context focus --seed 1 --deterministic --out-dir "${MGC_EVIDENCE_DIR}" \
            > "${MGC_ARTIFACTS_DIR}/drop2.json"
          diff -u "${MGC_ARTIFACTS_DIR}/drop1.json" "${MGC_ARTIFACTS_DIR}/drop2.json"

      - name: Web player build (bootstrap manifest -> drop -> collect audio -> synth playlist -> build)
        shell: bash
        env:
          MGC_DB: ${{ env.MGC_DB }}
          MGC_DETERMINISTIC: "1"
          MGC_FIXED_TIME: "2020-01-01T00:00:00Z"
        run: |
          set -euxo pipefail

          OUT_DIR="${RUNNER_TEMP}/mgc_web"
          SRC_DIR="${RUNNER_TEMP}/mgc_web_src"
          TRACKS_DIR="${SRC_DIR}/tracks"
          mkdir -p "${OUT_DIR}" "${SRC_DIR}" "${TRACKS_DIR}"
          export SRC_DIR

          # cmd_run_drop hashes ${out_dir}/manifest.json. Create a minimal one here.
          python - <<'PY'
          import json, os
          from datetime import datetime, timezone

          out_dir = os.environ["SRC_DIR"]
          fixed = os.environ.get("MGC_FIXED_TIME") or datetime.now(timezone.utc).isoformat()
          manifest = {
              "schema": "mgc.manifest.v1",
              "created_ts": fixed,
              "notes": "CI-generated minimal manifest to satisfy cmd_run_drop precondition",
          }
          path = os.path.join(out_dir, "manifest.json")
          with open(path, "w", encoding="utf-8") as f:
              json.dump(manifest, f, sort_keys=True, indent=2)
              f.write("\n")
          print("wrote", path)
          PY

          test -f "${SRC_DIR}/manifest.json"
          python -m json.tool < "${SRC_DIR}/manifest.json" >/dev/null

          # Run drop (may write audio elsewhere; stdout JSON may contain paths)
          python -m mgc.main run drop \
            --context focus \
            --seed 1 \
            --deterministic \
            --out-dir "${SRC_DIR}" \
            > "${SRC_DIR}/drop_stdout.json"
          python -m json.tool < "${SRC_DIR}/drop_stdout.json" >/dev/null

          # Collect audio paths from drop_stdout.json + common repo locations, then copy into TRACKS_DIR
          python - <<'PY'
          import json, os, pathlib, shutil, sys
          from collections import OrderedDict

          src_dir = pathlib.Path(os.environ["SRC_DIR"])
          tracks_dir = src_dir / "tracks"
          tracks_dir.mkdir(parents=True, exist_ok=True)

          drop_json = src_dir / "drop_stdout.json"
          data = json.loads(drop_json.read_text(encoding="utf-8"))

          exts = (".wav", ".mp3")

          def walk(obj):
              if isinstance(obj, dict):
                  for v in obj.values():
                      yield from walk(v)
              elif isinstance(obj, list):
                  for v in obj:
                      yield from walk(v)
              elif isinstance(obj, str):
                  yield obj

          candidates = []
          for s in walk(data):
              s2 = s.strip()
              if s2.lower().endswith(exts):
                  candidates.append(s2)

          # Normalize + keep only existing files
          existing = OrderedDict()
          for p in candidates:
              pp = pathlib.Path(p)
              if pp.exists() and pp.is_file():
                  existing[str(pp.resolve())] = pp.resolve()

          # Fallback search: common locations in the repo checkout
          # (drop may write to data/tracks or similar)
          repo_root = pathlib.Path(".").resolve()
          for base in [repo_root / "data", repo_root]:
              if not base.exists():
                  continue
              for ext in exts:
                  for p in base.rglob(f"*{ext}"):
                      # avoid huge env dirs if any
                      if ".venv" in p.parts or "site-packages" in p.parts:
                          continue
                      existing.setdefault(str(p.resolve()), p.resolve())

          if not existing:
              print("ERROR: could not locate any audio files (.wav/.mp3) after run drop", file=sys.stderr)
              print("drop_stdout.json keys sample:", file=sys.stderr)
              if isinstance(data, dict):
                  print(list(data.keys())[:50], file=sys.stderr)
              sys.exit(2)

          # Copy into SRC_DIR/tracks with stable names
          copied = []
          for i, p in enumerate(existing.values(), start=1):
              dst = tracks_dir / f"track_{i:03d}{p.suffix.lower()}"
              shutil.copy2(p, dst)
              copied.append(dst)

          print("copied_audio_count", len(copied))
          for p in copied[:25]:
              print("copied", p)
          PY

          # Synthesize a playlist JSON from the copied audio (guaranteed to live under SRC_DIR/tracks)
          PLAYLIST_JSON="${SRC_DIR}/ci_playlist.json"
          python - <<'PY'
          import json, os, pathlib, sys
          from datetime import datetime, timezone

          src_dir = pathlib.Path(os.environ["SRC_DIR"])
          tracks_dir = src_dir / "tracks"
          fixed = os.environ.get("MGC_FIXED_TIME") or datetime.now(timezone.utc).isoformat()

          audio = sorted([p for p in tracks_dir.iterdir() if p.is_file() and p.suffix.lower() in (".mp3", ".wav")])
          if not audio:
              print("ERROR: no audio files present in", tracks_dir, file=sys.stderr)
              sys.exit(2)

          tracks = []
          for i, p in enumerate(audio, start=1):
              # Use relative paths so web build can copy them cleanly; also include a few common field names.
              rel = str(p.relative_to(src_dir))
              tracks.append({
                  "id": f"ci-track-{i}",
                  "title": p.stem,
                  "path": rel,
                  "file": rel,
                  "src": rel,
              })

          playlist = {
              "schema": "mgc.playlist.v1",
              "id": "ci-playlist",
              "name": "ci_web_smoke",
              "created_ts": fixed,
              "track_count": len(tracks),
              "tracks": tracks,
          }

          out_path = src_dir / "ci_playlist.json"
          out_path.write_text(json.dumps(playlist, sort_keys=True, indent=2) + "\n", encoding="utf-8")
          print("wrote", out_path)
          print("track_count", len(tracks))
          PY

          test -s "${PLAYLIST_JSON}"
          python -m json.tool < "${PLAYLIST_JSON}" >/dev/null

          # Build web player. Use --strip-paths so relative track paths are resolved inside the build.
          python -m mgc.main web build \
            --playlist "${PLAYLIST_JSON}" \
            --out-dir "${OUT_DIR}" \
            --prefer-mp3 \
            --strip-paths \
            --clean \
            --fail-if-empty \
            --json \
            | python -m json.tool

          test "$(find "${OUT_DIR}" -maxdepth 6 -type f -name 'index.html' | wc -l)" -ge 1
          test "$(find "${OUT_DIR}" -maxdepth 8 -type f \( -name '*.mp3' -o -name '*.wav' \) | wc -l)" -ge 1

          # Debug context
          ls -la "${OUT_DIR}" || true
          find "${OUT_DIR}" -maxdepth 4 -type f -name 'index.html' -print || true
          find "${OUT_DIR}" -maxdepth 8 -type f \( -name '*.mp3' -o -name '*.wav' \) | head -n 25

      - name: Ensure working tree is clean (no generated artifacts)
        shell: bash
        run: |
          set -euo pipefail
          git status --porcelain=v1
          test -z "$(git status --porcelain=v1)"

      - name: Upload artifacts (on failure)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: ci-artifacts
          path: |
            ${{ env.MGC_ARTIFACTS_DIR }}
            ${{ env.MGC_EVIDENCE_DIR }}
            ${{ runner.temp }}/mgc_web
            ${{ runner.temp }}/mgc_web_src
            /tmp/mgc_drop.json
            /tmp/mgc_drops_list.json
            /tmp/mgc_drops_show.json
          if-no-files-found: ignore
